"""
ë‰´ìŠ¤ ì²´ì¸ - ë‰´ìŠ¤ ìˆ˜ì§‘ ë° ê°ì„± ë¶„ì„
- SERP API ë˜ëŠ” RSSë¥¼ í†µí•œ ë‰´ìŠ¤ ìˆ˜ì§‘
- AI ê¸°ë°˜ ë‰´ìŠ¤ ìš”ì•½ ë° ê°ì„± ë¶„ì„
- íŠ¸ë ˆì´ë”© ê´€ë ¨ì„± í•„í„°ë§
- ê²°ê³¼ ìºì‹± (2ì‹œê°„ ì£¼ê¸°)
"""
import json
import time
import requests
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional
from langchain.prompts import ChatPromptTemplate
from langchain.schema import HumanMessage, SystemMessage

from config import Config
from llm_factory import create_llm
from utils.db import get_chain_db, log_chain
from utils.retry_utils import retry_on_llm_error

class NewsChain:
    """ë‰´ìŠ¤ ìˆ˜ì§‘ ë° ë¶„ì„ ì²´ì¸"""
    
    def __init__(self):
        """ì´ˆê¸°í™”"""
        self.db = get_chain_db()
        self.model_name = Config.get_chain_model("news")
        self.settings = Config.get_chain_settings("news")
        self.serp_api_key = Config.SERP_API_KEY
        
        # LLM ìƒì„±
        try:
            self.llm = create_llm(self.model_name, **self.settings)
            log_chain("news", "INFO", f"Initialized with model: {self.model_name}")
        except Exception as e:
            log_chain("news", "ERROR", f"Failed to initialize LLM: {e}")
            raise
        
        # í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿
        self.analysis_prompt = ChatPromptTemplate.from_messages([
            ("system", """You are a cryptocurrency news analyst specializing in Bitcoin market sentiment analysis.

Analyze the provided news articles and provide a comprehensive summary focused on trading implications.

Your analysis must include:
1. Overall market sentiment (bullish/bearish/neutral)
2. Key themes and categories (regulation, adoption, technical, macro)
3. Impact assessment on BTC price
4. Relevance score for trading decisions

Respond in JSON format:
{
  "sentiment": "bullish/bearish/neutral",
  "sentiment_score": 0.0-1.0,
  "key_themes": ["theme1", "theme2"],
  "categories": {
    "regulation": {"count": 0, "sentiment": "neutral"},
    "adoption": {"count": 0, "sentiment": "neutral"},
    "technical": {"count": 0, "sentiment": "neutral"},
    "macro": {"count": 0, "sentiment": "neutral"}
  },
  "impact_assessment": "brief description of likely price impact",
  "trading_relevance": 0.0-1.0,
  "summary": "2-3 sentence summary of key points",
  "risk_factors": ["factor1", "factor2"]
}

Use sentiment_score: 0.0-0.3 (bearish), 0.3-0.7 (neutral), 0.7-1.0 (bullish)
Use trading_relevance: 0.0-0.3 (low), 0.3-0.7 (medium), 0.7-1.0 (high)"""),
            ("human", "Analyze these Bitcoin news articles:\n\n{news_articles}")
        ])
    
    def run(self, force_refresh: bool = False) -> Dict[str, Any]:
        """
        ë‰´ìŠ¤ ì²´ì¸ ì‹¤í–‰
        
        Args:
            force_refresh: ìºì‹œ ë¬´ì‹œí•˜ê³  ê°•ì œ ê°±ì‹ 
            
        Returns:
            ë‰´ìŠ¤ ë¶„ì„ ê²°ê³¼
        """
        start_time = time.time()
        
        try:
            # ìºì‹œëœ ê²°ê³¼ í™•ì¸ (force_refreshê°€ ì•„ë‹Œ ê²½ìš°)
            if not force_refresh:
                cached_result = self.db.get_latest_news_summary()
                if cached_result:
                    log_chain("news", "INFO", "Using cached news summary")
                    return {
                        "success": True,
                        "source": "cache",
                        "timestamp": cached_result["timestamp"],
                        "data": cached_result["summary"],
                        "sentiment_score": cached_result["sentiment_score"],
                        "articles_count": cached_result["articles_count"]
                    }
            
            # ë‰´ìŠ¤ ìˆ˜ì§‘
            log_chain("news", "INFO", "Collecting fresh news articles")
            articles = self._collect_news()
            
            if not articles:
                log_chain("news", "WARNING", "No news articles collected")
                return self._empty_result("No news articles available")
            
            # AI ë¶„ì„
            log_chain("news", "INFO", f"Analyzing {len(articles)} articles")
            analysis_result = self._analyze_news(articles)
            
            # ê²°ê³¼ ì €ìž¥
            self.db.save_news_summary(
                articles_count=len(articles),
                summary_data=analysis_result,
                sentiment_score=analysis_result.get("sentiment_score", 0.5)
            )
            
            processing_time = time.time() - start_time
            log_chain("news", "INFO", f"News analysis completed in {processing_time:.2f}s")
            
            return {
                "success": True,
                "source": "fresh",
                "timestamp": datetime.now().isoformat(),
                "data": analysis_result,
                "sentiment_score": analysis_result.get("sentiment_score", 0.5),
                "articles_count": len(articles),
                "processing_time": processing_time
            }
            
        except Exception as e:
            log_chain("news", "ERROR", f"News chain failed: {e}")
            return self._error_result(str(e))
    
    def _collect_news(self) -> List[Dict[str, str]]:
        """ë‰´ìŠ¤ ìˆ˜ì§‘ (SERP API ìš°ì„ , ì‹¤íŒ¨ì‹œ RSS ë°±ì—…)"""
        try:
            # SERP API ì‹œë„
            if self.serp_api_key:
                articles = self._collect_from_serp()
                if articles:
                    return articles
                log_chain("news", "WARNING", "SERP API failed, trying RSS backup")
            
            # RSS ë°±ì—…
            return self._collect_from_rss()
            
        except Exception as e:
            log_chain("news", "ERROR", f"News collection failed: {e}")
            return []
    
    def _collect_from_serp(self) -> List[Dict[str, str]]:
        """SERP APIë¥¼ í†µí•œ ë‰´ìŠ¤ ìˆ˜ì§‘"""
        try:
            url = "https://serpapi.com/search.json"
            params = {
                "engine": "google_news",
                "q": "bitcoin cryptocurrency BTC",
                "gl": "us",
                "hl": "en",
                "num": 15,
                "api_key": self.serp_api_key
            }
            
            response = requests.get(url, params=params, timeout=15)
            
            if response.status_code == 200:
                data = response.json()
                news_results = data.get("news_results", [])
                
                articles = []
                for news in news_results:
                    article = {
                        "title": news.get("title", ""),
                        "source": news.get("source", ""),
                        "date": news.get("date", ""),
                        "snippet": news.get("snippet", "")
                    }
                    if article["title"]:  # ì œëª©ì´ ìžˆëŠ” ê²½ìš°ë§Œ ì¶”ê°€
                        articles.append(article)
                
                log_chain("news", "INFO", f"Collected {len(articles)} articles from SERP")
                return articles
            else:
                log_chain("news", "ERROR", f"SERP API error: {response.status_code}")
                return []
                
        except Exception as e:
            log_chain("news", "ERROR", f"SERP collection error: {e}")
            return []
    
    def _collect_from_rss(self) -> List[Dict[str, str]]:
        """RSSë¥¼ í†µí•œ ë‰´ìŠ¤ ìˆ˜ì§‘ (ë°±ì—…)"""
        try:
            # CoinDesk RSS (ì‹ ë¢°í•  ìˆ˜ ìžˆëŠ” ì†ŒìŠ¤)
            rss_urls = [
                "https://www.coindesk.com/arc/outboundfeeds/rss/",
                "https://cointelegraph.com/rss",
            ]
            
            articles = []
            
            for rss_url in rss_urls:
                try:
                    response = requests.get(rss_url, timeout=10)
                    if response.status_code == 200:
                        # ê°„ë‹¨í•œ RSS íŒŒì‹± (ì‹¤ì œë¡œëŠ” feedparser ì‚¬ìš© ê¶Œìž¥)
                        content = response.text
                        
                        # ì œëª©ë§Œ ì¶”ì¶œí•˜ëŠ” ê°„ë‹¨í•œ ë°©ë²•
                        import re
                        titles = re.findall(r'<title><!\[CDATA\[(.*?)\]\]></title>', content)
                        if not titles:
                            titles = re.findall(r'<title>(.*?)</title>', content)
                        
                        for title in titles[:10]:  # ìµœëŒ€ 10ê°œ
                            if any(keyword.lower() in title.lower() for keyword in ["bitcoin", "btc", "crypto"]):
                                articles.append({
                                    "title": title,
                                    "source": rss_url.split("//")[1].split("/")[0],
                                    "date": datetime.now().strftime("%Y-%m-%d"),
                                    "snippet": ""
                                })
                        
                        if len(articles) >= 10:
                            break
                            
                except Exception as e:
                    log_chain("news", "WARNING", f"RSS source failed {rss_url}: {e}")
                    continue
            
            log_chain("news", "INFO", f"Collected {len(articles)} articles from RSS")
            return articles
            
        except Exception as e:
            log_chain("news", "ERROR", f"RSS collection error: {e}")
            return []
    
    @retry_on_llm_error(max_retries=2)
    def _analyze_news(self, articles: List[Dict[str, str]]) -> Dict[str, Any]:
        """AIë¥¼ í†µí•œ ë‰´ìŠ¤ ë¶„ì„"""
        try:
            # ë‰´ìŠ¤ ê¸°ì‚¬ë“¤ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
            news_text = ""
            for i, article in enumerate(articles, 1):
                news_text += f"{i}. {article['title']}"
                if article['snippet']:
                    news_text += f" - {article['snippet']}"
                if article['source']:
                    news_text += f" ({article['source']})"
                news_text += "\n"
            
            # AI ë¶„ì„ ìš”ì²­
            messages = self.analysis_prompt.format_messages(news_articles=news_text)
            response = self.llm.invoke(messages)
            
            # JSON ì‘ë‹µ íŒŒì‹±
            response_text = response.content.strip()
            
            # JSON ì‘ë‹µ ì •ë¦¬
            if "```json" in response_text:
                start_idx = response_text.find("```json") + 7
                end_idx = response_text.find("```", start_idx)
                if end_idx != -1:
                    response_text = response_text[start_idx:end_idx].strip()
            elif "```" in response_text:
                parts = response_text.split("```")
                if len(parts) >= 3:
                    response_text = parts[1].strip()
            
            analysis_result = json.loads(response_text)
            
            # ê²°ê³¼ ê²€ì¦ ë° ê¸°ë³¸ê°’ ì„¤ì •
            analysis_result = self._validate_analysis_result(analysis_result)
            
            log_chain("news", "INFO", f"Analysis completed - Sentiment: {analysis_result['sentiment']}")
            return analysis_result
            
        except json.JSONDecodeError as e:
            log_chain("news", "ERROR", f"Failed to parse AI response: {e}")
            return self._fallback_analysis(articles)
        except Exception as e:
            log_chain("news", "ERROR", f"News analysis failed: {e}")
            return self._fallback_analysis(articles)
    
    def _validate_analysis_result(self, result: Dict[str, Any]) -> Dict[str, Any]:
        """ë¶„ì„ ê²°ê³¼ ê²€ì¦ ë° ê¸°ë³¸ê°’ ì„¤ì •"""
        # í•„ìˆ˜ í•„ë“œ ê¸°ë³¸ê°’
        defaults = {
            "sentiment": "neutral",
            "sentiment_score": 0.5,
            "key_themes": [],
            "categories": {
                "regulation": {"count": 0, "sentiment": "neutral"},
                "adoption": {"count": 0, "sentiment": "neutral"},
                "technical": {"count": 0, "sentiment": "neutral"},
                "macro": {"count": 0, "sentiment": "neutral"}
            },
            "impact_assessment": "Neutral market impact expected",
            "trading_relevance": 0.5,
            "summary": "Mixed news sentiment with no clear directional bias",
            "risk_factors": []
        }
        
        # ê¸°ë³¸ê°’ìœ¼ë¡œ ì±„ìš°ê¸°
        for key, default_value in defaults.items():
            if key not in result:
                result[key] = default_value
        
        # ê°’ ë²”ìœ„ ê²€ì¦
        result["sentiment_score"] = max(0.0, min(1.0, result.get("sentiment_score", 0.5)))
        result["trading_relevance"] = max(0.0, min(1.0, result.get("trading_relevance", 0.5)))
        
        # sentiment ê°’ ê²€ì¦
        if result["sentiment"] not in ["bullish", "bearish", "neutral"]:
            result["sentiment"] = "neutral"
        
        return result
    
    def _fallback_analysis(self, articles: List[Dict[str, str]]) -> Dict[str, Any]:
        """AI ë¶„ì„ ì‹¤íŒ¨ì‹œ í´ë°± ë¶„ì„"""
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜ ê°ì„± ë¶„ì„
        bullish_keywords = ["adoption", "institutional", "etf", "bullish", "surge", "rise", "positive"]
        bearish_keywords = ["regulation", "ban", "crash", "bearish", "decline", "negative", "concern"]
        
        bullish_score = 0
        bearish_score = 0
        
        for article in articles:
            text = (article["title"] + " " + article.get("snippet", "")).lower()
            
            for keyword in bullish_keywords:
                if keyword in text:
                    bullish_score += 1
            
            for keyword in bearish_keywords:
                if keyword in text:
                    bearish_score += 1
        
        # ê°ì„± ê²°ì •
        if bullish_score > bearish_score:
            sentiment = "bullish"
            sentiment_score = 0.6 + min(0.3, (bullish_score - bearish_score) * 0.1)
        elif bearish_score > bullish_score:
            sentiment = "bearish"
            sentiment_score = 0.4 - min(0.3, (bearish_score - bullish_score) * 0.1)
        else:
            sentiment = "neutral"
            sentiment_score = 0.5
        
        return {
            "sentiment": sentiment,
            "sentiment_score": sentiment_score,
            "key_themes": ["fallback_analysis"],
            "categories": {
                "regulation": {"count": bearish_score, "sentiment": "bearish" if bearish_score > 0 else "neutral"},
                "adoption": {"count": bullish_score, "sentiment": "bullish" if bullish_score > 0 else "neutral"},
                "technical": {"count": 0, "sentiment": "neutral"},
                "macro": {"count": 0, "sentiment": "neutral"}
            },
            "impact_assessment": f"Simple keyword analysis: {sentiment}",
            "trading_relevance": 0.3,  # ë‚®ì€ ì‹ ë¢°ë„
            "summary": f"Fallback analysis based on keyword sentiment. {len(articles)} articles analyzed.",
            "risk_factors": ["fallback_analysis_used"]
        }
    
    def _empty_result(self, reason: str) -> Dict[str, Any]:
        """ë¹ˆ ê²°ê³¼ ë°˜í™˜"""
        return {
            "success": False,
            "source": "empty",
            "reason": reason,
            "timestamp": datetime.now().isoformat(),
            "data": {
                "sentiment": "neutral",
                "sentiment_score": 0.5,
                "summary": "No news data available"
            },
            "sentiment_score": 0.5,
            "articles_count": 0
        }
    
    def _error_result(self, error_msg: str) -> Dict[str, Any]:
        """ì—ëŸ¬ ê²°ê³¼ ë°˜í™˜"""
        return {
            "success": False,
            "source": "error",
            "error": error_msg,
            "timestamp": datetime.now().isoformat(),
            "data": {
                "sentiment": "neutral",
                "sentiment_score": 0.5,
                "summary": "Error occurred during news analysis"
            },
            "sentiment_score": 0.5,
            "articles_count": 0
        }


# íŽ¸ì˜ í•¨ìˆ˜
def run_news_analysis(force_refresh: bool = False) -> Dict[str, Any]:
    """ë‰´ìŠ¤ ë¶„ì„ ì‹¤í–‰ íŽ¸ì˜ í•¨ìˆ˜"""
    chain = NewsChain()
    return chain.run(force_refresh)


def get_latest_news_sentiment() -> float:
    """ìµœì‹  ë‰´ìŠ¤ ê°ì„± ì ìˆ˜ë§Œ ë°˜í™˜"""
    db = get_chain_db()
    news_summary = db.get_latest_news_summary()
    if news_summary:
        return news_summary["sentiment_score"]
    return 0.5  # ì¤‘ë¦½


def print_news_summary() -> None:
    """ë‰´ìŠ¤ ìš”ì•½ ì •ë³´ ì¶œë ¥"""
    db = get_chain_db()
    news_summary = db.get_latest_news_summary()
    
    if news_summary:
        data = news_summary["summary"]
        print(f"\nðŸ“° News Summary ({news_summary['articles_count']} articles)")
        print(f"Sentiment: {data['sentiment']} ({data['sentiment_score']:.2f})")
        print(f"Summary: {data['summary']}")
        print(f"Trading Relevance: {data.get('trading_relevance', 0.5):.2f}")
    else:
        print("\nðŸ“° No recent news summary available")