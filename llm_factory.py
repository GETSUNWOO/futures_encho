"""
LLM Factory ëª¨ë“ˆ
- ë‹¤ì¤‘ AI ëª¨ë¸ í†µí•© ê´€ë¦¬
- OpenAI, Anthropic, Google ëª¨ë¸ ì§€ì›
- LangChain ê¸°ë°˜ í†µì¼ëœ ì¸í„°í˜ì´ìŠ¤ ì œê³µ
"""
import os
from typing import Dict, Any, Optional
from langchain_openai import ChatOpenAI
from langchain_anthropic import ChatAnthropic
from langchain_google_genai import ChatGoogleGenerativeAI


class LLMFactory:
    """AI ëª¨ë¸ ìƒì„± ë° ê´€ë¦¬ íŒ©í† ë¦¬ í´ë˜ìŠ¤"""
    
    # ì§€ì›ë˜ëŠ” ëª¨ë¸ ì •ì˜
    SUPPORTED_MODELS = {
        # OpenAI ëª¨ë¸ë“¤
        "gpt-4o": {"provider": "openai", "model_name": "gpt-4o"},
        "gpt-4o-mini": {"provider": "openai", "model_name": "gpt-4o-mini"},
        "gpt-4-turbo": {"provider": "openai", "model_name": "gpt-4-turbo"},
        
        # Anthropic ëª¨ë¸ë“¤
        "claude-3-5-sonnet": {"provider": "anthropic", "model_name": "claude-3-5-sonnet-20241022"},
        "claude-3-5-haiku": {"provider": "anthropic", "model_name": "claude-3-5-haiku-20241022"},
        "claude-3-opus": {"provider": "anthropic", "model_name": "claude-3-opus-20240229"},
        
        # Google ëª¨ë¸ë“¤
        "gemini-2.0-flash": {"provider": "google", "model_name": "gemini-2.0-flash-exp"},
        "gemini-1.5-pro": {"provider": "google", "model_name": "gemini-1.5-pro"},
        "gemini-1.5-flash": {"provider": "google", "model_name": "gemini-1.5-flash"}
    }
    
    # ê¸°ë³¸ ì„¤ì •ê°’
    DEFAULT_SETTINGS = {
        "temperature": 0.1,
        "max_tokens": 2000,
        "timeout": 30
    }
    
    @classmethod
    def create_llm(cls, model_key: str, **kwargs) -> Any:
        """
        ì§€ì •ëœ ëª¨ë¸í‚¤ë¡œ LLM ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        
        Args:
            model_key: ëª¨ë¸ ì‹ë³„í‚¤ (ì˜ˆ: "gpt-4o", "claude-3-5-sonnet")
            **kwargs: ì¶”ê°€ ëª¨ë¸ ì„¤ì • (temperature, max_tokens ë“±)
            
        Returns:
            LangChain LLM ì¸ìŠ¤í„´ìŠ¤
            
        Raises:
            ValueError: ì§€ì›ë˜ì§€ ì•ŠëŠ” ëª¨ë¸ì´ê±°ë‚˜ API í‚¤ê°€ ì—†ëŠ” ê²½ìš°
        """
        if model_key not in cls.SUPPORTED_MODELS:
            raise ValueError(f"Unsupported model: {model_key}. "
                           f"Supported models: {list(cls.SUPPORTED_MODELS.keys())}")
        
        model_info = cls.SUPPORTED_MODELS[model_key]
        provider = model_info["provider"]
        model_name = model_info["model_name"]
        
        # ê¸°ë³¸ ì„¤ì •ê³¼ ì‚¬ìš©ì ì„¤ì • ë³‘í•©
        settings = {**cls.DEFAULT_SETTINGS, **kwargs}
        
        # í”„ë¡œë°”ì´ë”ë³„ LLM ìƒì„±
        if provider == "openai":
            return cls._create_openai_llm(model_name, settings)
        elif provider == "anthropic":
            return cls._create_anthropic_llm(model_name, settings)
        elif provider == "google":
            return cls._create_google_llm(model_name, settings)
        else:
            raise ValueError(f"Unknown provider: {provider}")
    
    @classmethod
    def _create_openai_llm(cls, model_name: str, settings: Dict[str, Any]) -> ChatOpenAI:
        """OpenAI LLM ìƒì„±"""
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            raise ValueError("OPENAI_API_KEY environment variable is required")
        
        return ChatOpenAI(
            model=model_name,
            api_key=api_key,
            temperature=settings["temperature"],
            max_tokens=settings["max_tokens"],
            timeout=settings["timeout"]
        )
    
    @classmethod
    def _create_anthropic_llm(cls, model_name: str, settings: Dict[str, Any]) -> ChatAnthropic:
        """Anthropic LLM ìƒì„±"""
        api_key = os.getenv("ANTHROPIC_API_KEY")
        if not api_key:
            raise ValueError("ANTHROPIC_API_KEY environment variable is required")
        
        return ChatAnthropic(
            model=model_name,
            api_key=api_key,
            temperature=settings["temperature"],
            max_tokens=settings["max_tokens"],
            timeout=settings["timeout"]
        )
    
    @classmethod
    def _create_google_llm(cls, model_name: str, settings: Dict[str, Any]) -> ChatGoogleGenerativeAI:
        """Google LLM ìƒì„±"""
        api_key = os.getenv("GOOGLE_API_KEY") or os.getenv("GEMINI_API_KEY")
        if not api_key:
            raise ValueError("GOOGLE_API_KEY or GEMINI_API_KEY environment variable is required")
        
        return ChatGoogleGenerativeAI(
            model=model_name,
            google_api_key=api_key,
            temperature=settings["temperature"],
            max_output_tokens=settings["max_tokens"],
            timeout=settings["timeout"]
        )
    
    @classmethod
    def get_supported_models(cls) -> list:
        """ì§€ì›ë˜ëŠ” ëª¨ë“  ëª¨ë¸ í‚¤ ë°˜í™˜"""
        return list(cls.SUPPORTED_MODELS.keys())
    
    @classmethod
    def get_model_info(cls, model_key: str) -> Dict[str, str]:
        """íŠ¹ì • ëª¨ë¸ì˜ ìƒì„¸ ì •ë³´ ë°˜í™˜"""
        if model_key not in cls.SUPPORTED_MODELS:
            raise ValueError(f"Unknown model: {model_key}")
        
        model_info = cls.SUPPORTED_MODELS[model_key].copy()
        
        # í”„ë¡œë°”ì´ë”ë³„ ì¶”ê°€ ì •ë³´
        provider = model_info["provider"]
        if provider == "openai":
            model_info.update({
                "display_name": f"OpenAI {model_key.upper()}",
                "context_window": "128k" if "gpt-4" in model_key else "32k",
                "cost_tier": "premium" if "gpt-4o" in model_key else "standard"
            })
        elif provider == "anthropic":
            model_info.update({
                "display_name": f"Anthropic {model_key.replace('-', ' ').title()}",
                "context_window": "200k",
                "cost_tier": "premium" if "opus" in model_key else "standard"
            })
        elif provider == "google":
            model_info.update({
                "display_name": f"Google {model_key.replace('-', ' ').title()}",
                "context_window": "1M" if "2.0" in model_key else "2M",
                "cost_tier": "budget" if "flash" in model_key else "standard"
            })
        
        return model_info
    
    @classmethod
    def validate_api_keys(cls) -> Dict[str, bool]:
        """ëª¨ë“  í”„ë¡œë°”ì´ë”ì˜ API í‚¤ ì¡´ì¬ ì—¬ë¶€ í™•ì¸"""
        return {
            "openai": bool(os.getenv("OPENAI_API_KEY")),
            "anthropic": bool(os.getenv("ANTHROPIC_API_KEY")),
            "google": bool(os.getenv("GOOGLE_API_KEY") or os.getenv("GEMINI_API_KEY"))
        }
    
    @classmethod
    def print_available_models(cls) -> None:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ë“¤ì„ ê¹”ë”í•˜ê²Œ ì¶œë ¥"""
        api_status = cls.validate_api_keys()
        
        print("\n" + "="*60)
        print("           ğŸ¤– AVAILABLE AI MODELS")
        print("="*60)
        
        by_provider = {}
        for model_key, info in cls.SUPPORTED_MODELS.items():
            provider = info["provider"]
            if provider not in by_provider:
                by_provider[provider] = []
            by_provider[provider].append(model_key)
        
        for provider, models in by_provider.items():
            status = "âœ…" if api_status[provider] else "âŒ"
            provider_name = provider.title()
            print(f"\n{status} {provider_name}:")
            
            for model in models:
                model_info = cls.get_model_info(model)
                cost_icon = {"budget": "ğŸ’°", "standard": "ğŸ’³", "premium": "ğŸ’"}.get(
                    model_info.get("cost_tier", "standard"), "ğŸ’³"
                )
                print(f"   {cost_icon} {model}")
        
        print("\n" + "="*60)
        if not all(api_status.values()):
            print("â— Missing API keys:")
            for provider, available in api_status.items():
                if not available:
                    key_name = {"openai": "OPENAI_API_KEY", 
                              "anthropic": "ANTHROPIC_API_KEY",
                              "google": "GOOGLE_API_KEY or GEMINI_API_KEY"}[provider]
                    print(f"   - {key_name}")
        print()


# í¸ì˜ í•¨ìˆ˜ë“¤
def create_llm(model_key: str, **kwargs):
    """LLM ìƒì„± í¸ì˜ í•¨ìˆ˜"""
    return LLMFactory.create_llm(model_key, **kwargs)


def get_available_models():
    """ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ëª©ë¡ ë°˜í™˜ í¸ì˜ í•¨ìˆ˜"""
    return LLMFactory.get_supported_models()


def print_models():
    """ëª¨ë¸ ëª©ë¡ ì¶œë ¥ í¸ì˜ í•¨ìˆ˜"""
    LLMFactory.print_available_models()


# í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
def test_model(model_key: str, test_prompt: str = "Hello, how are you?") -> bool:
    """
    íŠ¹ì • ëª¨ë¸ì„ í…ŒìŠ¤íŠ¸
    
    Args:
        model_key: í…ŒìŠ¤íŠ¸í•  ëª¨ë¸
        test_prompt: í…ŒìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸
        
    Returns:
        í…ŒìŠ¤íŠ¸ ì„±ê³µ ì—¬ë¶€
    """
    try:
        llm = create_llm(model_key)
        response = llm.invoke(test_prompt)
        print(f"âœ… {model_key}: {response.content[:50]}...")
        return True
    except Exception as e:
        print(f"âŒ {model_key}: {str(e)[:50]}...")
        return False


if __name__ == "__main__":
    # ì‚¬ìš© ì˜ˆì‹œ ë° í…ŒìŠ¤íŠ¸
    print_models()
    
    # ê°„ë‹¨í•œ ì—°ê²° í…ŒìŠ¤íŠ¸ (API í‚¤ê°€ ìˆëŠ” ê²½ìš°ì—ë§Œ)
    api_status = LLMFactory.validate_api_keys()
    if any(api_status.values()):
        print("\nğŸ§ª Testing available models...")
        for model_key in LLMFactory.get_supported_models():
            provider = LLMFactory.SUPPORTED_MODELS[model_key]["provider"]
            if api_status[provider]:
                test_model(model_key)